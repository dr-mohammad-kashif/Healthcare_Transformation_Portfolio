# What Healthcare Dashboards Show â€” and What They Quietly Leave Out

Dashboards provide clarity for healthcare organizations. One screen displays the activities, performance, and trends that could take hours to view. While this is useful for busy teams to quickly see the information, there is a potential downside that is frequently overlooked; dashboards are simplifying reality by design.

Most dashboards show count-based information (e.g., volume of visits), rate-based information (e.g., utilization percentage) and trend-based information (e.g., month-to-month changes). These metrics are excellent beginning points for identifying patterns and trends and identifying areas that need attention. However, dashboards are generally not very effective at showing how these numbers were produced.

Few dashboards will explain the circumstances under which the data was collected. Frequently omitted are staffing shortages, workflow changes, reporting delay issues, and documentation backlog issues, all of which can result in different numbers being reported even when the actual underlying performance has not changed. The lack of an explanation of these circumstances makes a single chart appear to be telling a much stronger story about performance than the actual evidence really supports.

Additionally, many dashboards omit variability. Dashboards typically aggregate data to keep it easily readable. Average, median, total, etc. allow for the management of large complex systems into one easily viewed screen. However, aggregating data eliminates the variability among the data. It is possible for a metric that appears to be relatively stable to conceal wide variations in performance among departments, locations, or user groups. Without the ability to segment the data, it is easy to overlook where friction or risk is occurring.

Dashboards also typically treat the definition of a metric as a static object. Even though the definition of a metric evolves, once defined it is treated as unchanging. Changes to coding rules, inclusion/exclusion criteria, and/or the source of the data can change the definition of what a particular number represents, but does not affect its visual appearance on the screen. If the definition changes are not documented adjacent to the visualization, then comparisons made over time become less reliable than they appear.

Most importantly, dashboards seldom represent uncertainty; confidence intervals, data completeness and recognized limitations are typically excluded. Therefore, the data appears precise, creating an illusion of finality that encourages over-confidence in decision making.

Reading dashboards properly requires using dashboards as discussion topics rather than as definitive conclusions. A number of questions to ask while interpreting data from dashboards may be:

What is not being measured by this dashboard?
Upon which assumptions is this metric based?
Has something changed upstream that would explain this trend?

Although dashboards can be effective tools, they are not neutral reporters. Dashboards represent the selection of items to display, simplification of complex issues and exclusion of certain information. As such, teams that acknowledge these boundaries will likely produce more effective decisions than teams that assume a clean and visually appealing chart represents all relevant information.

## Note - Non-Clinical

This explainer is intended for informational and educational purposes only and addresses general concepts of interpreting healthcare data, and not clinical, diagnostic or treatment guidelines.
